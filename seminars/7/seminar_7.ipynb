{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046f6e1b-110e-4016-82f1-fcd3227215e3",
   "metadata": {},
   "source": [
    "# Семинар 7: Оценка качества моделей, кросс-валидация, подбор метапараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6feff6-4020-4d22-8747-1ce7a79c1e57",
   "metadata": {},
   "source": [
    "На предыдущем семинаре мы рассмотрели основной рецепт применения модели машинного обучения под наблюдением:\n",
    "\n",
    "1. Выберите класс модели\n",
    "2. Выбрать гиперпараметры модели\n",
    "3. Подогнать модель к обучающим данным\n",
    "4. Используйте модель для предсказания меток для новых данных.\n",
    "\n",
    "Первые две части - выбор модели и выбор гиперпараметров - являются, пожалуй, самой важной частью эффективного использования этих инструментов и методов.\n",
    "Чтобы сделать обоснованный выбор, нам нужен способ *подтвердить*, что наша модель и наши гиперпараметры хорошо подходят к данным.\n",
    "Хотя это может показаться простым, есть несколько подводных камней, которых следует избегать, чтобы сделать это эффективно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53571f55-0f4e-466e-bafc-eab233ed66ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Оценка качества моделей: неправильный подход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29670709-a723-491c-8bb6-fa754589bcc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad1f16-75f5-454b-a41a-214bf579cf76",
   "metadata": {
    "tags": []
   },
   "source": [
    "Выбираем модель и гиперпараметры. Здесь мы будем использовать *KNeighborsClassifier* с ``n_neighbors=1``.\n",
    "Это очень простая и интуитивно понятная модель, которая говорит, что \"метка неизвестной точки совпадает с меткой ее ближайшей обучающей точки:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e746cd78-28fd-4168-acbd-b86448c7c363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23d9c2e4-c4a3-48c7-8f18-7e28bf80df2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_model = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b2f9b84-afb9-442b-a222-bd7794986eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce3403-5bb1-49f6-b323-9a375a6aa79a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Мы видим оценку точности 1,0, что означает, что 100% точек были правильно помечены нашей моделью!\n",
    "Но действительно ли это измерение ожидаемой точности? \n",
    "Действительно ли мы нашли модель, которая, как мы ожидаем, будет правильной в 100% случаев?\n",
    "\n",
    "Как вы уже догадались, ответ отрицательный.\n",
    "На самом деле, этот подход содержит фундаментальный недостаток: *он обучает и оценивает модель на одних и тех же данных*.\n",
    "Более того, модель ближайшего соседа - это *оценка на основе случая*, которая просто хранит обучающие данные и предсказывает метки, сравнивая новые данные с этими сохраненными точками: за исключением надуманных случаев, она будет давать 100% точность *каждый раз*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff387c-d011-4d3a-8890-bb862c6d6f1f",
   "metadata": {},
   "source": [
    "### Оценка качества моделей: валидация на отложенной выборке\n",
    "\n",
    "Лучшее представление о производительности модели можно получить, используя так называемый *холд-аут набор*: то есть, мы удерживаем некоторое подмножество данных от обучения модели, а затем используем этот холд-аут набор для проверки производительности модели.\n",
    "Такое разбиение можно сделать с помощью утилиты ``train_test_split`` в Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5cd337-954d-4a24-8bc6-29c54b30b79c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split the data with 50% in each set\n",
    "X1, X2, y1, y2 = train_test_split(X, y, random_state=0,\n",
    "                                  train_size=0.5)\n",
    "\n",
    "# fit the model on one set of data\n",
    "model.fit(X1, y1)\n",
    "\n",
    "# evaluate the model on the second set of data\n",
    "y2_model = model.predict(X2)\n",
    "accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5cf46b-3ced-469f-8966-80327817c52a",
   "metadata": {},
   "source": [
    "### Оценка качества моделей: перекрестная валидация\n",
    "\n",
    "Одним из недостатков использования набора данных для проверки модели является то, что мы потеряли часть данных для обучения модели.\n",
    "В приведенном выше случае половина набора данных не участвует в обучении модели!\n",
    "Это не оптимально и может вызвать проблемы - особенно если начальный набор обучающих данных невелик.\n",
    "\n",
    "Одним из способов решения этой проблемы является использование *перекрестной валидации*; то есть, проведение последовательности подгонок, в которых каждое подмножество данных используется и как обучающий набор, и как проверочный набор.\n",
    "Визуально это может выглядеть примерно так:\n",
    "\n",
    "![](images/05.03-2-fold-CV.png)\n",
    "\n",
    "Здесь мы проводим два проверочных испытания, поочередно используя каждую половину данных в качестве промежуточного набора.\n",
    "Используя разделенные данные, мы могли бы реализовать это следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85529287-9e56-4949-82d9-0e939c08ee56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96, 0.9066666666666666)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_model = model.fit(X1, y1).predict(X2)\n",
    "y1_model = model.fit(X2, y2).predict(X1)\n",
    "accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9da3c7-8a26-441a-8f28-a34bf37206eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "В результате получаются две оценки точности, которые мы можем объединить (например, взяв среднее значение), чтобы получить более точную оценку эффективности глобальной модели.\n",
    "Эта конкретная форма кросс-валидации является *двухкратной кросс-валидацией*, то есть, когда мы разделили данные на два набора и использовали каждый из них по очереди в качестве проверочного набора.\n",
    "\n",
    "Мы можем расширить эту идею, чтобы использовать еще больше испытаний и больше складок в данных - например, вот визуальное изображение пятикратной кросс-валидации:\n",
    "\n",
    "![](images/05.03-5-fold-CV.png)\n",
    "\n",
    "Здесь мы разбиваем данные на пять групп и используем каждую из них по очереди для оценки соответствия модели на остальных 4/5 данных.\n",
    "Это было бы довольно утомительно делать вручную, поэтому мы можем использовать удобную процедуру Scikit-Learn ``cross_val_score'', чтобы сделать это лаконично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c6a84a-6bc4-44da-bf7d-5da8a665e7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.93333333, 0.93333333, 1.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3c5fc7-13aa-4f08-8c1c-54de5f09defc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3533fd59-c1d3-4c27-9ed2-cb809ef6b3aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "scores = cross_val_score(model, X, y, cv=LeaveOneOut())\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2f38041-a972-49ca-a386-ab419e841994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62083e2-d498-47a0-b5d6-ccd3f3bd4b9f",
   "metadata": {},
   "source": [
    "### Выбор лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef539866-93ff-4d6d-ac45-c03fc0da8cec",
   "metadata": {},
   "source": [
    "Теперь, когда мы рассмотрели основы валидации и перекрестной валидации, мы немного углубимся в выбор модели и подбор гиперпараметров.\n",
    "Эти вопросы являются одними из самых важных аспектов практики машинного обучения, и я обнаружил, что в вводных учебниках по машинному обучению эта информация часто упускается.\n",
    "\n",
    "Основное значение имеет следующий вопрос: *если наша оценка не оправдывает себя, как мы должны двигаться дальше?\n",
    "Есть несколько возможных ответов:\n",
    "\n",
    "- Использовать более сложную/более гибкую модель\n",
    "- Использовать менее сложную/менее гибкую модель\n",
    "- Собрать больше обучающих выборок\n",
    "- Собрать больше данных, чтобы добавить характеристики к каждой выборке.\n",
    "\n",
    "Ответ на этот вопрос часто бывает контринтуитивным.\n",
    "В частности, иногда использование более сложной модели дает худшие результаты, а добавление большего количества обучающих выборок может не улучшить ваши результаты!\n",
    "Способность определить, какие шаги улучшат вашу модель, - это то, что отделяет успешных практиков машинного обучения от неуспешных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d729db4-bc80-4dc8-8e25-84ac762dea18",
   "metadata": {},
   "source": [
    "### The Bias-variance trade-off. Дилемма смещения и дисперсии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045a12a-8c75-4172-8ab7-09b9529d21f8",
   "metadata": {},
   "source": [
    "![](images/05.03-validation-curve.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d290514-07dd-4cbc-b2fc-71b21ed87d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
